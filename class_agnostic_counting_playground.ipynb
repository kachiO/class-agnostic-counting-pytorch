{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:26.107249Z",
     "start_time": "2020-03-19T09:53:25.952720Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:35.816995Z",
     "start_time": "2020-03-19T09:53:35.631361Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, pdb, numpy as np, matplotlib.pyplot as plt, torch.nn as nn, random, os\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:08:08.971226Z",
     "start_time": "2020-03-16T20:08:08.884211Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage import gaussian_filter, affine_transform\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Normalize, RandomAffine, RandomHorizontalFlip, CenterCrop, ToTensor, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:08:11.276453Z",
     "start_time": "2020-03-16T20:08:11.142327Z"
    }
   },
   "outputs": [],
   "source": [
    "data_info_dir = Path('../imagenet_vid/')\n",
    "with np.load(data_info_dir/'imagenet.npz', allow_pickle=True) as data:\n",
    "    trn_list = data['trn_lst']\n",
    "    trn_lb = data['trn_lb']\n",
    "    val_list = data['val_lst']\n",
    "    val_lb = data['val_lb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:12:17.154238Z",
     "start_time": "2020-03-16T20:12:17.051818Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../imagenet_vid/train.npy', trn_list)\n",
    "np.save('../imagenet_vid/valid.npy', val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:08:24.382396Z",
     "start_time": "2020-03-16T20:08:24.368331Z"
    }
   },
   "outputs": [],
   "source": [
    "imgdims = (255, 255, 3)\n",
    "patchdims = (63, 63, 3)\n",
    "outputdims = (64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:08:33.249877Z",
     "start_time": "2020-03-16T20:08:33.241912Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "IMAGENET_VID_DIMS = dict(\n",
    "    image = (255, 255, 3),\n",
    "    patch = (63, 63, 3),\n",
    "    output = (64, 64, 1))\n",
    "\n",
    "DATA_MAP = {'a': 'ILSVRC2015_VID_train_0000',\n",
    "            'b': 'ILSVRC2015_VID_train_0001', \n",
    "            'c': 'ILSVRC2015_VID_train_0002',\n",
    "            'd': 'ILSVRC2015_VID_train_0003',\n",
    "            'e': 'val'}\n",
    "\n",
    "DATA_ROOT = '/home/odoemoo1/data/mldata/Imagenet_Video_2015/ILSVRC2015/crop_255_exemplar_63_context_0.1/'\n",
    "\n",
    "IMAGENET_STATS = dict(mean = (0.485, 0.456, 0.406), \n",
    "                      std = (0.229, 0.224, 0.225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:08:37.392551Z",
     "start_time": "2020-03-16T20:08:37.380755Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "generic_transforms = [ToTensor(), Normalize(**IMAGENET_STATS, inplace=True), ]\n",
    "patch_transforms = [RandomAffine(degrees=(8, 20), translate=[0.1, 0.1], scale=[0.95, 1.05]),\n",
    "                    RandomHorizontalFlip(0.5),\n",
    "                    CenterCrop(IMAGENET_VID_DIMS['patch'][:2]), \n",
    "                    ]\n",
    "patch_tfms = Compose(patch_transforms + generic_transforms)\n",
    "generic_tfms = Compose(generic_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:30:41.039914Z",
     "start_time": "2020-03-16T20:30:41.022154Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class ImagenetVidDatatset(Dataset):\n",
    "    def __init__(self, data_root=DATA_ROOT, data_meta_dir='../imagenet_vid/', mode='train',\n",
    "                 dims=IMAGENET_VID_DIMS, p_match=0.5, patch_augment=True, imagenet_norm=True):\n",
    "        self.root = data_root\n",
    "        self.dims = dims\n",
    "        self.p_match = p_match\n",
    "        self.patch_augment = patch_augment\n",
    "        assert mode in ['train', 'valid']\n",
    "        self.data = np.load(Path(data_meta_dir) / f'{mode}.npy', allow_pickle=True)\n",
    "\n",
    "        positive = np.zeros(self.dims['output'])\n",
    "        positive[self.dims['output'][0] // 2, self.dims['output'][1] // 2, 0] = 1\n",
    "        positive[:, :, 0] = 100 * gaussian_filter(positive[:, :, 0], sigma=(2, 2), mode='constant')\n",
    "        self.output = np.concatenate((positive, np.zeros(self.dims['output'])), -1)\n",
    "        self.tfms = generic_tfms\n",
    "        self.patch_tfms = patch_tfms if self.patch_augment else generic_tfms\n",
    "        self.imagenet_norm= imagenet_norm\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_obj = np.random.choice(self.data[index])\n",
    "        _video_dir, object_id, frames = Path(input_obj[0]), input_obj[1], input_obj[2]\n",
    "        video_dir = Path(self.root) / DATA_MAP[str(_video_dir.parent)] / _video_dir.name\n",
    "\n",
    "        if np.random.rand() < self.p_match:\n",
    "            # positive pair\n",
    "            patch_obj = input_obj\n",
    "            _patch_dir, patch_object_id, patch_frames = Path(input_obj[0]), input_obj[1], input_obj[2]\n",
    "            \n",
    "            # choose two frames at most 100 frames apart\n",
    "            start_frame = np.random.randint(max(1, len(frames) - 100))\n",
    "            frame_in, frame_ex = np.random.choice(frames[start_frame : start_frame + 100], 2)\n",
    "            output_map = self.output[:, :, 0]\n",
    "            match = True\n",
    "        else:\n",
    "            # negative pair\n",
    "            new_index = np.random.choice(list(set(np.arange(len(self.data))) - set([index])))\n",
    "            patch_obj = np.random.choice(self.data[new_index])\n",
    "            _patch_dir, patch_object_id, patch_frames = Path(patch_obj[0]), patch_obj[1], patch_obj[2]\n",
    "                                                         \n",
    "            frame_in = np.random.choice(frames)\n",
    "            frame_ex = np.random.choice(patch_frames)\n",
    "            output_map = self.output[:, :, 1]\n",
    "            match = False\n",
    "\n",
    "        input_fn = video_dir / f'{frame_in:06}.{object_id:02}.x.jpg'\n",
    "        patch_dir = Path(self.root) / DATA_MAP[str(_patch_dir.parent)] / _patch_dir.name\n",
    "        patch_fn = patch_dir / f\"{frame_ex:06}.{patch_object_id:02}.{'x' if self.patch_augment else 'z'}.jpg\"\n",
    "\n",
    "        img_input = Image.open(input_fn)\n",
    "        img_patch = Image.open(patch_fn)\n",
    "\n",
    "        if self.imagenet_norm:\n",
    "            img_input = self.tfms(img_input)\n",
    "            img_patch = self.patch_tfms(img_patch)\n",
    "\n",
    "        output = {'search_img': img_input,\n",
    "                  'patch_img': img_patch,\n",
    "                  'output_map': output_map,\n",
    "                  'match': np.float(match)}\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:19:25.582036Z",
     "start_time": "2020-03-16T20:19:25.551860Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ImagenetVidDatatset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:19:26.058171Z",
     "start_time": "2020-03-16T20:19:26.009095Z"
    }
   },
   "outputs": [],
   "source": [
    "out = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:20:33.414473Z",
     "start_time": "2020-03-16T20:20:33.319632Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(out['output_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:30:59.207021Z",
     "start_time": "2020-03-16T20:30:59.072565Z"
    }
   },
   "outputs": [],
   "source": [
    "!git commit -m \"update\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:28:02.327601Z",
     "start_time": "2020-03-16T20:27:58.412689Z"
    }
   },
   "outputs": [],
   "source": [
    "!git push --set-upstream origin vgg-counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:37.902996Z",
     "start_time": "2020-03-19T09:53:37.826980Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "#from torchvision.models.resnet import Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:38.885531Z",
     "start_time": "2020-03-19T09:53:38.541294Z"
    }
   },
   "outputs": [],
   "source": [
    "res50 = resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:43.794976Z",
     "start_time": "2020-03-19T09:53:43.778914Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    def __init__(self, inplanes, chans, kernel_size=3, stride=1,  expansion=4, downsample=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        planes = [chans, chans, chans * expansion]\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes[0], kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes[0])\n",
    "        self.adapt = nn.Conv2d(planes[0], planes[1], kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(planes[0], planes[1], kernel_size=kernel_size, padding=(kernel_size-1)//2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes[1])\n",
    "        self.conv3 = nn.Conv2d(planes[1], planes[2], kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes[2])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.expansion = expansion\n",
    "        \n",
    "        # orthogonal initialization for adapt module\n",
    "        for m in self.adapt.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #print(m.weight.shape, m.weight.ndimension())\n",
    "                nn.init.orthogonal_(m.weight, gain=0.1)\n",
    "        \n",
    "        if downsample:\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes[-1], kernel_size=1, stride=stride, bias=False),\n",
    "                                          nn.BatchNorm2d(planes[-1]))\n",
    "                \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        adapt = self.adapt(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out += adapt\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:44.187250Z",
     "start_time": "2020-03-19T09:53:44.162486Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet50_Half(nn.Module):\n",
    "    def __init__(self, in_chans=3, layers=[3, 4], chans=[64, 128], strides=[1, 2], expansion=4):\n",
    "        super(ResNet50_Half, self).__init__()\n",
    "        self.block = Bottleneck\n",
    "        self.conv1 = nn.Conv2d(in_chans, chans[0], kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(chans[0])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.inplanes = chans[0]\n",
    "        self.expansion = expansion\n",
    "        \n",
    "        self.layer1 = self._make_layer(layers[0], chans[0], chans[0], stride=strides[0])\n",
    "        self.layer2 = self._make_layer(layers[1], self.inplanes, chans[1], stride=strides[1])\n",
    "        \n",
    "    def _make_layer(self, nblocks, in_planes, planes, stride=1, prefix=''):\n",
    "        layers = [self.block(in_planes, planes, stride=stride, downsample=True)]\n",
    "        self.inplanes = planes * self.expansion\n",
    "        layers += [self.block(self.inplanes, planes) for b in range(nblocks - 1)]\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:44.513875Z",
     "start_time": "2020-03-19T09:53:44.487153Z"
    }
   },
   "outputs": [],
   "source": [
    "base_encoder = ResNet50_Half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:45.044508Z",
     "start_time": "2020-03-19T09:53:44.889458Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 255,255)\n",
    "out = base_encoder(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:45.358182Z",
     "start_time": "2020-03-19T09:53:45.338126Z"
    }
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:45.838380Z",
     "start_time": "2020-03-19T09:53:45.825407Z"
    }
   },
   "outputs": [],
   "source": [
    "base_encoder.load_state_dict(res50.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:46.354125Z",
     "start_time": "2020-03-19T09:53:46.314025Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_block(nfin, nfout, ks, stride=1, padding=0, bias=False, bn=True, act_fn=None, convT=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Convolutional block with optional batch normalization and relu\n",
    "    \"\"\"\n",
    "    _conv_block_list = [nn.Conv2d(nfin, nfout, ks, stride, padding=padding, bias=bias)]\n",
    "    if convT:\n",
    "        _conv_block_list = [nn.ConvTranspose2d(nfin, nfout, ks, stride, padding=padding, bias=bias, **kwargs)]\n",
    "\n",
    "    if bn:\n",
    "        _conv_block_list += [nn.BatchNorm2d(nfout)]\n",
    "\n",
    "    if act_fn == 'relu':\n",
    "        _conv_block_list += [nn.ReLU(inplace=True)]\n",
    "\n",
    "    return nn.Sequential(*_conv_block_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:46.782914Z",
     "start_time": "2020-03-19T09:53:46.770523Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Relation_Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Relation module.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, out_planes=256):\n",
    "        super(Relation_Module, self).__init__()\n",
    "\n",
    "        self.conv1 = conv_block(in_planes, out_planes, ks=3, padding=1, act_fn='relu')\n",
    "        self.convT = conv_block(out_planes, out_planes, ks=3, stride=2, padding=1, convT=True, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.convT(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:47.285163Z",
     "start_time": "2020-03-19T09:53:47.230071Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.rand(1, 1024, 32, 32)\n",
    "module = Relation_Module(1024)\n",
    "out = module(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:47.662416Z",
     "start_time": "2020-03-19T09:53:47.649522Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class L2_Normalization(nn.Module):\n",
    "    \"\"\"\n",
    "    L2 normalization layer with learnable parameter.\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=True, eps=1e-6):\n",
    "        super(L2_Normalization, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = scale\n",
    "        self.alpha = 1 \n",
    "        \n",
    "        if self.scale:\n",
    "            self.alpha = nn.Parameter(torch.ones(1))\n",
    "            nn.init.uniform_(self.alpha, 10., 20.)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f'(eps={self.eps}, alpha={self.alpha.data.tolist()[0]:.04f})'\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        l2_norm = x / (torch.norm(x, p=2, dim=1, keepdim=True) + self.eps).expand_as(x)\n",
    "        l2_norm = self.alpha * l2_norm\n",
    "        \n",
    "        return l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:47.995618Z",
     "start_time": "2020-03-19T09:53:47.980272Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = nn.Parameter(torch.ones(1))\n",
    "nn.init.uniform_(alpha, 10., 20.)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:48.329107Z",
     "start_time": "2020-03-19T09:53:48.310999Z"
    }
   },
   "outputs": [],
   "source": [
    "l2 = L2_Normalization()\n",
    "out = l2(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:48.648472Z",
     "start_time": "2020-03-19T09:53:48.632032Z"
    }
   },
   "outputs": [],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:48.969924Z",
     "start_time": "2020-03-19T09:53:48.932294Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "config = OrderedDict(\n",
    "            encoder=OrderedDict(\n",
    "                            in_chans=3, \n",
    "                            layers=[3, 4], \n",
    "                            chans=[64, 128], \n",
    "                            strides=[1, 2], \n",
    "                            expansion=4),\n",
    "            relation=dict(planes=256),\n",
    "            l2norm=dict(scale=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:49.791226Z",
     "start_time": "2020-03-19T09:53:49.766248Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Generic_Matching_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic Matching Network from Lu et al 2018\n",
    "    Clas Agnostic Counting.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, pretrained=True):\n",
    "        super(Generic_Matching_Net, self).__init__()\n",
    "        self.encoder_patch = ResNet50_Half()\n",
    "        self.encoder_image = ResNet50_Half()\n",
    "        \n",
    "        if pretrained:\n",
    "            print('Loading imagenet weights.')\n",
    "            from torchvision.models import resnet50\n",
    "            res50 = resnet50(pretrained=True)\n",
    "            self.encoder_patch.load_state_dict(res50.state_dict(), strict=False)\n",
    "            self.encoder_image.load_state_dict(res50.state_dict(), strict=False)\n",
    "            \n",
    "        self.encoder_patch = nn.Sequential(self.encoder_patch, nn.AdaptiveAvgPool2d(1))\n",
    "        self.l2_norm1 = L2_Normalization(config['l2norm']['scale'])\n",
    "        self.l2_norm2 = L2_Normalization(config['l2norm']['scale'])\n",
    "        in_planes = config['encoder']['chans'][-1] * config['encoder']['expansion'] * 2\n",
    "        self.matching = Relation_Module(in_planes, config['relation']['planes'])\n",
    "        self.prediction = conv_block(config['relation']['planes'], 1, ks=3, padding=1, bn=False, act_fn='relu')\n",
    "        \n",
    "    def forward(self, image, exemplar):\n",
    "        F_image = self.l2_norm1(self.encoder_image(image))\n",
    "        F_exemplar = self.l2_norm2(self.encoder_patch(exemplar))\n",
    "        F_exemplar = F_exemplar.expand_as(F_image).clone()\n",
    "        F = torch.cat((F_image, F_exemplar), dim=1)\n",
    "        \n",
    "        out = self.matching(F)\n",
    "        out = self.prediction(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:50.831021Z",
     "start_time": "2020-03-19T09:53:50.446626Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Generic_Matching_Net(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:51.499494Z",
     "start_time": "2020-03-19T09:53:51.396741Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, exp = torch.rand(1, 3, 255,255), torch.rand(1, 3, 63,63)\n",
    "out = model(img, exp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:53:52.143622Z",
     "start_time": "2020-03-19T09:53:51.960492Z"
    }
   },
   "outputs": [],
   "source": [
    "!python -m notebook2script class_agnostic_counting_playground.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:50:43.118593Z",
     "start_time": "2020-03-19T09:50:42.980242Z"
    }
   },
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:52:00.738513Z",
     "start_time": "2020-03-19T09:52:00.594653Z"
    }
   },
   "outputs": [],
   "source": [
    "!git commit -m \"code refactoring and conversion to scripts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:52:18.548790Z",
     "start_time": "2020-03-19T09:52:14.514476Z"
    }
   },
   "outputs": [],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T07:32:59.385994Z",
     "start_time": "2020-03-22T07:32:59.349189Z"
    }
   },
   "outputs": [],
   "source": [
    "from catalyst.dl import SupervisedRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T07:33:14.813624Z",
     "start_time": "2020-03-22T07:33:14.717554Z"
    }
   },
   "outputs": [],
   "source": [
    "??SupervisedRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T07:35:47.662816Z",
     "start_time": "2020-03-22T07:35:47.641049Z"
    }
   },
   "outputs": [],
   "source": [
    "??isinstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Bagnet version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T18:39:50.662168Z",
     "start_time": "2020-03-13T18:39:50.562865Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, kernel_size=1, expansion=4):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        # print('Creating bottleneck with kernel size {} and stride {} with padding {}'.format(kernel_size, stride, (kernel_size - 1) // 2))\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=kernel_size, stride=stride, padding=0, bias=False) # changed padding from (kernel_size - 1) // 2\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.expansion = expansion\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        if residual.size(-1) != out.size(-1):\n",
    "            diff = residual.size(-1) - out.size(-1)\n",
    "            residual = residual[:,:,:-diff,:-diff]\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BagNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, in_chans=3, strides=[1, 2, 2, 2], chans=[64, 128, 256, 512], dropouts=[0, 0], \n",
    "                 kernel3=[0, 0, 0, 0], expansion=4, num_classes=1000, avg_pool=True):\n",
    "        self.inplanes = chans[0]\n",
    "        super(BagNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chans, chans[0], kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.conv2 = nn.Conv2d(chans[0], chans[0], kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(chans[0], momentum=0.001)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.expansion = expansion\n",
    "        self.layer1 = self._make_layer(block, chans[0], layers[0], stride=strides[0], kernel3=kernel3[0], prefix='layer1')\n",
    "        self.layer2 = self._make_layer(block, chans[1], layers[1], stride=strides[1], kernel3=kernel3[1], prefix='layer2')\n",
    "        #self.layer3 = self._make_layer(block, chans[2], layers[2], stride=strides[2], kernel3=kernel3[2], prefix='layer3')\n",
    "        #self.layer4 = self._make_layer(block, chans[3], layers[3], stride=strides[3], kernel3=kernel3[3], prefix='layer4')\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropouts[0])\n",
    "        self.dropout2 = nn.Dropout(dropouts[1])\n",
    "        self.num_classes = num_classes\n",
    "        if self.num_classes:\n",
    "            self.avgpool = nn.AvgPool2d(1, stride=1)\n",
    "            self.fc = nn.Linear(chans[3] * self.expansion, num_classes)\n",
    "            self.avg_pool = avg_pool\n",
    "\n",
    "        self.block = block\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, kernel3=0, prefix=''):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * self.expansion:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.inplanes, planes * self.expansion,\n",
    "                                       kernel_size=1, stride=stride, bias=False),\n",
    "                                       nn.BatchNorm2d(planes * self.expansion))\n",
    "\n",
    "        layers = []\n",
    "        kernel = 1 if kernel3 == 0 else 3\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, kernel_size=kernel, expansion=self.expansion))\n",
    "        self.inplanes = planes * self.expansion\n",
    "        for i in range(1, blocks):\n",
    "            kernel = 1 if kernel3 <= i else 3\n",
    "            layers.append(block(self.inplanes, planes, kernel_size=kernel, expansion=self.expansion))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout1(self.layer1(x))\n",
    "        x = self.dropout1(self.layer2(x))\n",
    "    \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T18:48:41.462188Z",
     "start_time": "2020-03-13T18:48:41.411443Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "strides=[1, 2,]# 2, 1]\n",
    "model2 = BagNet(Bottleneck, [3, 4, ], strides=strides, kernel3=[3, 4, ], num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T18:48:41.865289Z",
     "start_time": "2020-03-13T18:48:41.843987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T18:48:44.980714Z",
     "start_time": "2020-03-13T18:48:43.163381Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = model2(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T18:18:34.380693Z",
     "start_time": "2020-03-13T18:16:37.083687Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T15:36:15.198149Z",
     "start_time": "2020-03-13T15:36:15.188894Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adapt = nn.Conv2d(3, 10, kernel_size=3, padding=(3-1)//2)\n",
    "for m in adapt.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.shape, m.weight.ndimension())\n",
    "        nn.init.orthogonal_(m.weight, gain=0.1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T15:36:17.076613Z",
     "start_time": "2020-03-13T15:36:17.064478Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 25,25)\n",
    "adapt(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, kernel_size=1, expansion=4):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        # print('Creating bottleneck with kernel size {} and stride {} with padding {}'.format(kernel_size, stride, (kernel_size - 1) // 2))\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=kernel_size, stride=stride, padding=0, bias=False) # changed padding from (kernel_size - 1) // 2\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.expansion = expansion\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        if residual.size(-1) != out.size(-1):\n",
    "            diff = residual.size(-1) - out.size(-1)\n",
    "            residual = residual[:,:,:-diff,:-diff]\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:microns-ml]",
   "language": "python",
   "name": "conda-env-microns-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
